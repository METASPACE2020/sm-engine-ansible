---

spark_key_file: ~/.ssh/ubuntu_spark

aws_access_key_id:
aws_secret_access_key:

postgres_version: 9.3

miniconda_version: latest
miniconda_python: 2
miniconda_prefix: "/opt/dev/miniconda"
miniconda_env:
  name: sm
  dependencies:
    - python=2
    - numpy=1.10
    - scipy=0.16
    - matplotlib=1.5
    - pandas=0.18
    - cffi
    - gcc
    - psycopg2
    - pip:
      - pyMSpec
      - cpyMSpec
      - pyImagingMSpec
      - cpyImagingMSpec
      - requests
      - mock
      - py4j
      - pyimzML
      - pytest
      - tornado
      - tornpsql
      - recommonmark
      - boto3
      - networkx
      - fabric
      - supervisor

sm_branch: "master"
sm_postgres_password: "1234"
sm_home: "/opt/dev/sm"
sm_s3_path: "s3a://sm-engine/data"

hmdb_url: "https://s3-eu-west-1.amazonaws.com/sm-engine/hmdb.csv"
activate_venv: source {{ miniconda_prefix }}/bin/activate {{ miniconda_env.name }}

spark_version: "1.6.0-bin-hadoop2.7.1"
spark_mirror: "https://s3-eu-west-1.amazonaws.com/sm-engine/dev"
spark_home: "/usr/lib/spark"

spark_env_extras_slave:
  SPARK_WORKER_DIR: "/tmp/spark"
  SPARK_LOCAL_DIRS: "/tmp/spark"
  PYSPARK_PYTHON: "{{ miniconda_prefix }}/envs/{{ miniconda_env.name }}/bin/python"

spark_env_extras_master:
  AWS_ACCESS_KEY_ID: "{{ aws_access_key_id }}"
  AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
  PYSPARK_PYTHON: "{{ miniconda_prefix }}/envs/{{ miniconda_env.name }}/bin/python"